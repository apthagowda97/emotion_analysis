{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from input_feeder import InputFeeder\n",
    "from face_detection import FaceDetection\n",
    "from emotions_recognition import EmotionsRecognition\n",
    "from face_reidentification import FaceReidentification\n",
    "\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir =  os.path.split(os.getcwd())[0]\n",
    "\n",
    "input_video = os.path.join(parent_dir,'input_video','netflix.mp4')\n",
    "\n",
    "input_feeder = InputFeeder('video',input_video)\n",
    "input_feeder.load_data()\n",
    "\n",
    "face_detection= FaceDetection()\n",
    "face_detection.load_model()\n",
    "\n",
    "emotions_recognition = EmotionsRecognition()\n",
    "emotions_recognition.load_model()\n",
    "\n",
    "face_reidentification = FaceReidentification()\n",
    "face_reidentification.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions = {0:'neutral',1:'happy',2:'sadness',3:'surprise',4:'anger'}\n",
    "faces_db = {}\n",
    "emotions_db = {}\n",
    "face_vectors_db = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_(face,face_emotion,face_vector):\n",
    "    \n",
    "    similarity = [0]\n",
    "    for face_vector_cmp in face_vectors_db:\n",
    "        similarity.append(cosine_similarity(face_vector,face_vector_cmp))\n",
    "    \n",
    "    if max(similarity)>0.5:\n",
    "        faces_db[np.argmax(similarity)-1].append(face)\n",
    "        emotions_db[np.argmax(similarity)-1].append(face_emotion)\n",
    "        \n",
    "    else:\n",
    "        face_vectors_db.append(face_vector)\n",
    "        faces_db[len(faces_db)] = [face]\n",
    "        emotions_db[len(emotions_db)] = [face_emotion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_faces_db():\n",
    "    print(f\"The number face detected are: {len(faces_db)}\")\n",
    "    plt.figure(figsize=(20,10))\n",
    "    for index,face in faces_db.items():\n",
    "        img = cv2.resize(face[0], (50,50))\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(1,len(faces_db),index+1)\n",
    "        plt.imshow(img,interpolation='bilinear')\n",
    "        plt.title(f\"FACE_{index}\")\n",
    "        plt.axis(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emotion_emoji(face_emotion,cord,bbox_frame):\n",
    "    l = cord[0]\n",
    "    m = cord[0]+20\n",
    "    n = cord[1]+cord[3]-20\n",
    "    o = cord[1]+cord[3]\n",
    "    bbox_frame[n:o,l:m,:] = cv2.resize(cv2.imread(os.path.join(parent_dir,'bin',f'{emotions[face_emotion]}.png')),(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_emotion_count(bbox_frame,emotions_count):\n",
    "    fig = Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    ax = fig.gca()\n",
    "    ax.axis('off')\n",
    "    ax.set_ylim(0,len(emotions_count))\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    ax.set_frame_on(False)\n",
    "    ax.bar(emotions.values(),emotions_count,color='red')\n",
    "    canvas.draw()\n",
    "    w, h = (fig.get_size_inches() * fig.get_dpi()).astype(int)\n",
    "    x = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(h,w,3)\n",
    "    x = cv2.resize(x, (216,144))\n",
    "    bbox_frame[276:420,504:720,2] = np.where(x[:,:,2]==0,255,frame[276:420,504:720,2])\n",
    "    bbox_frame[420:450,534:564,:] = cv2.resize(cv2.imread(os.path.join(parent_dir,'bin','neutral.png')),(30,30))\n",
    "    bbox_frame[420:450,568:598,:] = cv2.resize(cv2.imread(os.path.join(parent_dir,'bin','happy.png')),(30,30))\n",
    "    bbox_frame[420:450,602:632,:] = cv2.resize(cv2.imread(os.path.join(parent_dir,'bin','sadness.png')),(30,30))\n",
    "    bbox_frame[420:450,636:666,:] = cv2.resize(cv2.imread(os.path.join(parent_dir,'bin','surprise.png')),(30,30))\n",
    "    bbox_frame[420:450,670:700,:] = cv2.resize(cv2.imread(os.path.join(parent_dir,'bin','anger.png')),(30,30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_video = os.path.join(parent_dir,'output_video','netflix.mp4')\n",
    "out = cv2.VideoWriter(output_video, 0x00000021, 18, (720,480))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in input_feeder.next_batch():\n",
    "    if frame is None:\n",
    "        break\n",
    "    emotions_count = [0,0,0,0,0]\n",
    "    bbox_frame,faces,cords = face_detection.predict(frame)\n",
    "    for index,face in enumerate(faces):\n",
    "        face_emotion = emotions_recognition.predict(face)\n",
    "        face_vector  = face_reidentification.predict(face)\n",
    "        add_emotion_emoji(face_emotion,cords[index],bbox_frame)\n",
    "        update_(face,face_emotion,face_vector)\n",
    "        emotions_count[face_emotion] += 1\n",
    "    plot_emotion_count(bbox_frame,emotions_count)\n",
    "    out.write(bbox_frame)\n",
    "\n",
    "out.release()\n",
    "input_feeder.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=\"720\" height=\"480\" controls>\n",
       "  <source src=\"../output_video/netflix.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=\"720\" height=\"480\" controls>\n",
    "  <source src=\"../output_video/netflix.mp4\" type=\"video/mp4\">\n",
    "</video>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "5009cf75-8734-4244-9fa5-3760b2a332d2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
